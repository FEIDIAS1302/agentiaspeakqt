import streamlit as st
import requests
from deep_translator import GoogleTranslator
import whisper
import os
import difflib
import io

# --- ãƒšãƒ¼ã‚¸è¨­å®š & ãƒ‡ã‚¶ã‚¤ãƒ³ ---
st.set_page_config(page_title="AGENTIA for QTnet Î²", layout="wide") # æ¨ªä¸¦ã³ã®ãŸã‚ã«wideã«è¨­å®š

st.markdown("""
    <style>
    header {visibility: hidden;}
    .main .block-container { max-width: 1000px; padding-top: 2rem; }
    .quality-badge { padding: 4px 12px; border-radius: 4px; font-weight: bold; }
    .pass { background-color: #d4edda; color: #155724; }
    .fail { background-color: #f8d7da; color: #721c24; }
    .stButton>button { 
        background-color: #004e92; 
        color: white; 
        border-radius: 6px;
    }
    /* ã‚¹ãƒˆãƒƒã‚¯ã‚«ãƒ¼ãƒ‰ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    .stock-card {
        border: 1px solid #ddd;
        padding: 10px;
        border-radius: 8px;
        margin-bottom: 10px;
        background-color: #f9f9f9;
    }
    </style>
    """, unsafe_allow_html=True)

# --- ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ– (éŸ³å£°ã‚¹ãƒˆãƒƒã‚¯ç”¨) ---
if "audio_stock" not in st.session_state:
    st.session_state.audio_stock = []

# --- å†…éƒ¨è§£æé–¢æ•° ---
@st.cache_resource
def load_whisper():
    return whisper.load_model("base")

def analyze_audio(audio_bytes, target_text):
    temp_file = "temp_audio.wav"
    with open(temp_file, "wb") as f:
        f.write(audio_bytes)
    try:
        model = load_whisper()
        result = model.transcribe(temp_file)
        transcribed_text = result["text"].strip()
        match_score = difflib.SequenceMatcher(None, target_text.lower(), transcribed_text.lower()).ratio()
        return {"transcribed": transcribed_text, "accuracy": match_score * 100}
    finally:
        if os.path.exists(temp_file):
            os.remove(temp_file)

# --- ãƒ¡ã‚¤ãƒ³ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ ---
col_main, col_stock = st.columns([1.2, 1]) # å·¦ã«æ“ä½œç³»ã€å³ã«ã‚¹ãƒˆãƒƒã‚¯

with col_main:
    if os.path.exists("logo.png"):
        st.image("logo.png", width=300)
    else:
        st.title("éŸ³å£°ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ")

    text_input = st.text_area("ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ› (æ—¥æœ¬èª)", placeholder="éŸ³å£°åŒ–ã—ãŸã„å†…å®¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„...", height=150)
    
    c1, c2 = st.columns(2)
    with c1:
        lang_option = st.selectbox("å‡ºåŠ›è¨€èª", ["æ—¥æœ¬èª", "è‹±èª", "ä¸­å›½èª", "ã‚¹ãƒšã‚¤ãƒ³èª", "éŸ“å›½èª"])
    with c2:
        # ãƒœã‚¤ã‚¹é¸æŠã‚’2ã¤ã«é™å®š
        voice_style = st.selectbox("éŸ³å£°ãƒ¢ãƒ‡ãƒ«", ["ç”·æ€§", "å¥³æ€§"])

    VOICE_MODELS = {
        "ç”·æ€§": "b8580c330cd74c2bbb7785815f1756d3",
        "å¥³æ€§": "735434a118054f65897638d4b7380dfc"
    }

    if st.button("éŸ³å£°ã‚’ç”Ÿæˆãƒ»æ¤œå“"):
        api_key = st.secrets.get("FISH_AUDIO_API_KEY")
        if not api_key:
            st.error("Secretsã« 'FISH_AUDIO_API_KEY' ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
        elif text_input:
            with st.spinner('AIç”Ÿæˆä¸­...'):
                try:
                    lang_map = {"æ—¥æœ¬èª": "ja", "è‹±èª": "en", "ä¸­å›½èª": "zh-CN", "ã‚¹ãƒšã‚¤ãƒ³èª": "es", "éŸ“å›½èª": "ko"}
                    translated = GoogleTranslator(source='ja', target=lang_map[lang_option]).translate(text_input)
                    
                    # APIãƒªã‚¯ã‚¨ã‚¹ãƒˆ (Fish Audio)
                    headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                    payload = {"text": translated, "format": "wav", "reference_id": VOICE_MODELS[voice_style]}
                    res = requests.post("https://api.fish.audio/v1/tts", headers=headers, json=payload)
                    
                    if res.status_code == 200:
                        audio_data = res.content
                        analysis = analyze_audio(audio_data, translated)
                        
                        # ã‚¹ãƒˆãƒƒã‚¯ã«è¿½åŠ  (æœ€å¤§5ã¤ã€æ–°ã—ã„ã‚‚ã®ã‚’ä¸Šã«)
                        new_item = {
                            "audio": audio_data,
                            "text": text_input[:20] + "...",
                            "lang": lang_option,
                            "acc": analysis['accuracy'],
                            "trans": analysis['transcribed']
                        }
                        st.session_state.audio_stock.insert(0, new_item)
                        if len(st.session_state.audio_stock) > 5:
                            st.session_state.audio_stock.pop()
                            
                        st.success("ç”Ÿæˆå®Œäº†ï¼å³å´ã®ã‚¹ãƒˆãƒƒã‚¯ã«è¿½åŠ ã•ã‚Œã¾ã—ãŸã€‚")
                    else:
                        st.error(f"APIã‚¨ãƒ©ãƒ¼: {res.status_code}")
                except Exception as e:
                    st.error(f"ã‚¨ãƒ©ãƒ¼: {e}")

# --- å³å´ï¼šéŸ³å£°ã‚¹ãƒˆãƒƒã‚¯ã‚¨ãƒªã‚¢ ---
with col_stock:
    st.subheader("ğŸµ ç”Ÿæˆæ¸ˆã¿ã‚¹ãƒˆãƒƒã‚¯ (æœ€æ–°5ä»¶)")
    if not st.session_state.audio_stock:
        st.info("ç”Ÿæˆã•ã‚ŒãŸéŸ³å£°ãŒã“ã“ã«è¡¨ç¤ºã•ã‚Œã¾ã™")
    
    for i, item in enumerate(st.session_state.audio_stock):
        with st.container():
            st.markdown(f"""
            <div class="stock-card">
                <small>{item['lang']} | ç²¾åº¦: {item['acc']:.1f}%</small><br>
                <strong>{item['text']}</strong>
            </div>
            """, unsafe_allow_html=True)
            
            st.audio(item['audio'])
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³ (ã‚­ãƒ¼ã‚’ãƒ¦ãƒ‹ãƒ¼ã‚¯ã«ã™ã‚‹ãŸã‚ã« i ã‚’ä½¿ç”¨)
            st.download_button(
                label=f"Download WAV #{i+1}",
                data=item['audio'],
                file_name=f"voice_{item['lang']}_{i}.wav",
                mime="audio/wav",
                key=f"dl_{i}"
            )
            st.markdown("---")

st.caption("Â© 2026 Powered by FEIDIAS Inc.")